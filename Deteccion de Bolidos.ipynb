{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ab0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "umbral_contorno = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0696c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_metadatos(video_path):\n",
    "    # Abre el archivo de video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Obtiene el número total de frames\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Obtiene el FPS (frames por segundo)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Obtiene las dimensiones del frame\n",
    "    ancho = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    alto = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    tamaño_frame = (ancho, alto)\n",
    "    duracion = total_frames / fps\n",
    "\n",
    "    # Cierra el video\n",
    "    cap.release()\n",
    "\n",
    "    return total_frames, fps, tamaño_frame,duracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130227ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frames: 71\n",
      "FPS: 24.781849912739965\n",
      "Dimensiones del frame: (1392, 1088)\n",
      "Duración del video: 2.865\n"
     ]
    }
   ],
   "source": [
    "video_path = \"perseida1.mp4\"\n",
    "total_frames, fps, tamaño_frame,duracion = obtener_metadatos(video_path)\n",
    "print(f\"Total de frames: {total_frames}\")\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Dimensiones del frame: {tamaño_frame}\")\n",
    "print(f\"Duración del video: {duracion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ffe621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa8db0",
   "metadata": {},
   "source": [
    "Definición de funciones para la detección de video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b8d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que superpone las imagenes de un array de imágenes\n",
    "\n",
    "from ipywidgets import widgets, HBox, VBox\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "\n",
    "def superimpose_images(frames):\n",
    "    \n",
    "    # np.maximum.reduce para obtener el valor máximo de píxeles entre todas las imágenes\n",
    "    resulting_image = np.maximum.reduce(frames)\n",
    "    return resulting_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59775b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mostrar la detección de movimiento en el notebook\n",
    "\n",
    "def mostrar_detección(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    output_widget = widgets.Output()\n",
    "    display(output_widget)\n",
    "    \n",
    "    total_frames, fps, tamaño_frame,duracion = obtener_metadatos(video_path)\n",
    "    \n",
    "    # inicialización de variables\n",
    "    \n",
    "    (x,y,w,h)=(0,0,0,0)\n",
    "    rectangulos=[]\n",
    "    frames = []\n",
    "    frames_deteccion = []\n",
    "    flag = False\n",
    "    last_frame = frame2\n",
    "\n",
    "    while cap.isOpened():\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=5)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            if cv2.contourArea(contour) < umbral_contorno:\n",
    "                continue\n",
    "                \n",
    "            rectangulos.append([x,y,w,h,cv2.contourArea(contour),w/h,h/w])\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "            frames.append(frame1)\n",
    "            \n",
    "            with output_widget:\n",
    "                clear_output(wait=True)\n",
    "                display(widgets.Image(value=cv2.imencode('.png', frame1)[1].tobytes()))\n",
    "\n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "       \n",
    "        # Wait 5 seconds\n",
    "       \n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if len(rectangulos) < 5:\n",
    "        resulting_image = last_frame\n",
    "    \n",
    "    else:\n",
    "            \n",
    "        # Obteniendo los índices para el patrón en el array principal\n",
    "        primero = 0\n",
    "        ultimo = len(rectangulos) - 1\n",
    "        medio = ultimo // 2\n",
    "        primer_intermedio = primero + (medio - primero) // 2\n",
    "        segundo_intermedio = medio + (ultimo - medio) // 2\n",
    "    \n",
    "        # Índices en el array principal\n",
    "        indices = [primero, primer_intermedio, medio, segundo_intermedio, ultimo]\n",
    "            \n",
    "        # Recorrer los subarrays en las posiciones definidas y pinta los rectangulos de la detección y la linea de la trayectoria\n",
    "    \n",
    "        x1 = rectangulos [0][0] + int(rectangulos [0][2]/2)\n",
    "        y1 = rectangulos [0][1] + int(rectangulos [0][3]/2)\n",
    "        \n",
    "        for i in indices:\n",
    "        \n",
    "            cv2.rectangle(frames[i], (rectangulos [i][0], rectangulos [i][1]), (rectangulos [i][0] + rectangulos [i][2], rectangulos [i][1] + rectangulos [i][3]), (0, 255, 0), 1)\n",
    "             \n",
    "            x2 = rectangulos [i][0] + int((rectangulos [i][2])/2)\n",
    "            y2 = rectangulos [i][1] + int((rectangulos [i][3])/2)\n",
    "                       \n",
    "            cv2.line(frames[i], (x1 , y1), (x2 , y2), (0, 255, 0), 1)\n",
    "     \n",
    "            frames_deteccion.append(frames[i])\n",
    "                                           \n",
    "            x1 = x2\n",
    "            y1 = y2\n",
    "        \n",
    "        resulting_image = superimpose_images(frames_deteccion)\n",
    "    \n",
    "    # Escribir metadatos video\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    org = (50, 50) # posición de inicio del texto\n",
    "    fontScale = 1 # tamaño de la fuente\n",
    "    color = (0, 255, 0) # color del texto en BGR\n",
    "    thickness = 2 # grosor de la línea\n",
    "    \n",
    "    lines = [\n",
    "    f\" Video: {video_path}\",\n",
    "    f\" Total frames: {total_frames}\",\n",
    "    f\" Frames detectados:{len(rectangulos)}\",\n",
    "    f\" Tiempo detectados (seg): {duracion}\"]\n",
    "\n",
    "    # Parámetros para cv2.putText\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    x_start = 10  # posición horizontal inicial\n",
    "    y_start = 50  # posición vertical inicial\n",
    "    y_offset = 30  # espacio entre líneas\n",
    "    fontScale = 0.7  # tamaño de la fuente\n",
    "    color = (0, 255, 0)  # color del texto en BGR\n",
    "    thickness = 1  # grosor de la línea\n",
    "\n",
    "    for line in lines:\n",
    "        cv2.putText(resulting_image, line, (x_start, y_start), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        y_start += y_offset\n",
    "\n",
    "    # Widget de visualización\n",
    "    \n",
    "    out = widgets.Output(layout={'border': '1px solid black'})\n",
    "    with out:\n",
    "        display(Image.fromarray(resulting_image))\n",
    "\n",
    "    display(out)\n",
    "    \n",
    "    cv2.imwrite(\"deteccion.png\",resulting_image)\n",
    "                        \n",
    "    return {'fps':fps,'rectangulos':rectangulos,'image':resulting_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f705b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825afe3239f645819fc34913ec5fee5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba5f08c8ec14584a494d4907f21d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'fps': 24.778331106522533,\n",
       " 'rectangulos': [[1150, 177, 25, 26, 512.0, 0.9615384615384616, 1.04],\n",
       "  [1140, 172, 26, 27, 548.0, 0.9629629629629629, 1.0384615384615385],\n",
       "  [1130, 169, 23, 27, 514.0, 0.8518518518518519, 1.173913043478261],\n",
       "  [1126, 167, 24, 28, 544.5, 0.8571428571428571, 1.1666666666666667],\n",
       "  [1118, 165, 24, 29, 561.0, 0.8275862068965517, 1.2083333333333333],\n",
       "  [1114, 165, 26, 28, 622.5, 0.9285714285714286, 1.0769230769230769],\n",
       "  [1100, 163, 29, 31, 703.5, 0.9354838709677419, 1.0689655172413792],\n",
       "  [1102, 163, 22, 30, 520.0, 0.7333333333333333, 1.3636363636363635],\n",
       "  [1091, 166, 24, 29, 571.5, 0.8275862068965517, 1.2083333333333333],\n",
       "  [1085, 166, 30, 32, 777.0, 0.9375, 1.0666666666666667],\n",
       "  [1083, 166, 27, 32, 681.0, 0.84375, 1.1851851851851851],\n",
       "  [1082, 169, 24, 32, 577.0, 0.75, 1.3333333333333333],\n",
       "  [1081, 169, 25, 30, 586.5, 0.8333333333333334, 1.2],\n",
       "  [1079, 168, 24, 31, 605.5, 0.7741935483870968, 1.2916666666666667],\n",
       "  [1076, 172, 24, 28, 567.5, 0.8571428571428571, 1.1666666666666667],\n",
       "  [1071, 173, 27, 29, 667.5, 0.9310344827586207, 1.0740740740740742],\n",
       "  [1064, 173, 31, 33, 825.0, 0.9393939393939394, 1.064516129032258],\n",
       "  [1062, 173, 29, 32, 757.5, 0.90625, 1.103448275862069],\n",
       "  [1062, 177, 26, 33, 638.0, 0.7878787878787878, 1.2692307692307692],\n",
       "  [1061, 178, 24, 30, 578.5, 0.8, 1.25],\n",
       "  [1058, 174, 25, 35, 701.0, 0.7142857142857143, 1.4],\n",
       "  [1054, 178, 26, 33, 680.0, 0.7878787878787878, 1.2692307692307692],\n",
       "  [1048, 182, 28, 33, 800.0, 0.8484848484848485, 1.1785714285714286],\n",
       "  [1040, 181, 33, 35, 947.5, 0.9428571428571428, 1.0606060606060606],\n",
       "  [1037, 181, 30, 36, 849.0, 0.8333333333333334, 1.2],\n",
       "  [1033, 183, 31, 39, 877.5, 0.7948717948717948, 1.2580645161290323],\n",
       "  [1030, 183, 31, 41, 944.5, 0.7560975609756098, 1.3225806451612903],\n",
       "  [1029, 183, 28, 42, 934.5, 0.6666666666666666, 1.5],\n",
       "  [1024, 184, 28, 40, 886.0, 0.7, 1.4285714285714286],\n",
       "  [1019, 189, 31, 36, 885.5, 0.8611111111111112, 1.1612903225806452],\n",
       "  [1011, 194, 34, 35, 965.5, 0.9714285714285714, 1.0294117647058822],\n",
       "  [1002, 195, 36, 37, 1059.0, 0.972972972972973, 1.0277777777777777],\n",
       "  [998, 196, 35, 40, 1036.5, 0.875, 1.1428571428571428],\n",
       "  [995, 198, 32, 42, 991.0, 0.7619047619047619, 1.3125],\n",
       "  [994, 198, 29, 44, 1008.5, 0.6590909090909091, 1.5172413793103448],\n",
       "  [989, 199, 29, 42, 996.5, 0.6904761904761905, 1.4482758620689655],\n",
       "  [983, 202, 31, 39, 976.5, 0.7948717948717948, 1.2580645161290323],\n",
       "  [975, 209, 36, 38, 1074.5, 0.9473684210526315, 1.0555555555555556],\n",
       "  [967, 211, 37, 40, 1185.5, 0.925, 1.0810810810810811],\n",
       "  [960, 213, 36, 42, 1162.0, 0.8571428571428571, 1.1666666666666667],\n",
       "  [957, 214, 35, 45, 1178.5, 0.7777777777777778, 1.2857142857142858],\n",
       "  [954, 215, 34, 47, 1208.5, 0.723404255319149, 1.3823529411764706],\n",
       "  [951, 217, 31, 46, 1154.0, 0.6739130434782609, 1.4838709677419355],\n",
       "  [945, 221, 33, 42, 1098.5, 0.7857142857142857, 1.2727272727272727],\n",
       "  [939, 227, 35, 41, 1096.5, 0.8536585365853658, 1.1714285714285715],\n",
       "  [930, 234, 36, 38, 1125.0, 0.9473684210526315, 1.0555555555555556],\n",
       "  [920, 236, 38, 40, 1202.0, 0.95, 1.0526315789473684],\n",
       "  [914, 238, 39, 44, 1236.0, 0.8863636363636364, 1.1282051282051282],\n",
       "  [909, 242, 40, 46, 1281.5, 0.8695652173913043, 1.15],\n",
       "  [905, 243, 38, 49, 1349.5, 0.7755102040816326, 1.2894736842105263],\n",
       "  [902, 245, 36, 51, 1414.5, 0.7058823529411765, 1.4166666666666667],\n",
       "  [897, 248, 36, 53, 1504.5, 0.6792452830188679, 1.4722222222222223],\n",
       "  [892, 253, 36, 53, 1524.0, 0.6792452830188679, 1.4722222222222223],\n",
       "  [885, 257, 36, 54, 1549.0, 0.6666666666666666, 1.5],\n",
       "  [878, 262, 37, 54, 1595.5, 0.6851851851851852, 1.4594594594594594],\n",
       "  [870, 266, 39, 55, 1655.0, 0.7090909090909091, 1.4102564102564104],\n",
       "  [863, 271, 40, 56, 1694.0, 0.7142857142857143, 1.4],\n",
       "  [856, 276, 40, 57, 1730.5, 0.7017543859649122, 1.425],\n",
       "  [848, 282, 42, 57, 1751.5, 0.7368421052631579, 1.3571428571428572],\n",
       "  [840, 287, 41, 57, 1790.0, 0.7192982456140351, 1.3902439024390243],\n",
       "  [833, 292, 41, 58, 1812.0, 0.7068965517241379, 1.4146341463414633],\n",
       "  [824, 299, 44, 57, 1849.0, 0.7719298245614035, 1.2954545454545454],\n",
       "  [816, 304, 42, 58, 1879.0, 0.7241379310344828, 1.380952380952381],\n",
       "  [807, 310, 44, 59, 1950.0, 0.7457627118644068, 1.3409090909090908],\n",
       "  [799, 316, 43, 60, 1929.0, 0.7166666666666667, 1.3953488372093024],\n",
       "  [789, 322, 45, 60, 1999.0, 0.75, 1.3333333333333333],\n",
       "  [780, 329, 42, 59, 1949.0, 0.711864406779661, 1.4047619047619047],\n",
       "  [770, 336, 44, 58, 1979.0, 0.7586206896551724, 1.3181818181818181],\n",
       "  [760, 343, 45, 57, 1976.0, 0.7894736842105263, 1.2666666666666666],\n",
       "  [750, 349, 45, 57, 1982.5, 0.7894736842105263, 1.2666666666666666],\n",
       "  [741, 356, 45, 57, 2023.5, 0.7894736842105263, 1.2666666666666666],\n",
       "  [731, 362, 47, 58, 2067.5, 0.8103448275862069, 1.2340425531914894],\n",
       "  [721, 368, 46, 58, 2065.0, 0.7931034482758621, 1.2608695652173914],\n",
       "  [711, 375, 47, 57, 2050.0, 0.8245614035087719, 1.2127659574468086],\n",
       "  [701, 381, 46, 57, 2046.0, 0.8070175438596491, 1.2391304347826086],\n",
       "  [691, 387, 47, 57, 2079.5, 0.8245614035087719, 1.2127659574468086],\n",
       "  [679, 394, 49, 57, 2094.0, 0.8596491228070176, 1.163265306122449],\n",
       "  [669, 400, 48, 57, 2106.0, 0.8421052631578947, 1.1875],\n",
       "  [658, 406, 50, 57, 2138.5, 0.8771929824561403, 1.14],\n",
       "  [647, 411, 50, 57, 2166.0, 0.8771929824561403, 1.14],\n",
       "  [636, 418, 50, 57, 2175.5, 0.8771929824561403, 1.14],\n",
       "  [625, 423, 51, 58, 2203.0, 0.8793103448275862, 1.1372549019607843],\n",
       "  [615, 429, 49, 59, 2200.0, 0.8305084745762712, 1.2040816326530612],\n",
       "  [604, 435, 48, 58, 2145.0, 0.8275862068965517, 1.2083333333333333],\n",
       "  [593, 441, 49, 58, 2127.5, 0.8448275862068966, 1.183673469387755],\n",
       "  [581, 448, 49, 57, 2109.0, 0.8596491228070176, 1.163265306122449],\n",
       "  [569, 455, 50, 54, 2058.0, 0.9259259259259259, 1.08],\n",
       "  [558, 461, 49, 53, 2013.0, 0.9245283018867925, 1.0816326530612246],\n",
       "  [548, 467, 49, 52, 1966.5, 0.9423076923076923, 1.0612244897959184],\n",
       "  [536, 473, 50, 51, 1958.5, 0.9803921568627451, 1.02],\n",
       "  [525, 478, 49, 51, 1967.0, 0.9607843137254902, 1.0408163265306123],\n",
       "  [514, 481, 49, 53, 2046.5, 0.9245283018867925, 1.0816326530612246],\n",
       "  [504, 484, 48, 55, 2082.0, 0.8727272727272727, 1.1458333333333333],\n",
       "  [494, 487, 48, 58, 2162.0, 0.8275862068965517, 1.2083333333333333],\n",
       "  [484, 490, 47, 60, 2173.5, 0.7833333333333333, 1.2765957446808511],\n",
       "  [474, 495, 47, 60, 2157.5, 0.7833333333333333, 1.2765957446808511],\n",
       "  [463, 500, 48, 58, 2130.5, 0.8275862068965517, 1.2083333333333333],\n",
       "  [453, 504, 48, 59, 2131.5, 0.8135593220338984, 1.2291666666666667],\n",
       "  [443, 509, 47, 59, 2118.5, 0.7966101694915254, 1.2553191489361701],\n",
       "  [432, 513, 48, 59, 2151.0, 0.8135593220338984, 1.2291666666666667],\n",
       "  [421, 517, 49, 59, 2196.5, 0.8305084745762712, 1.2040816326530612],\n",
       "  [411, 521, 50, 58, 2226.5, 0.8620689655172413, 1.16],\n",
       "  [402, 524, 50, 59, 2232.5, 0.847457627118644, 1.18],\n",
       "  [395, 526, 46, 64, 2183.5, 0.71875, 1.391304347826087],\n",
       "  [385, 528, 47, 69, 2201.5, 0.6811594202898551, 1.4680851063829787],\n",
       "  [375, 534, 47, 65, 2078.0, 0.7230769230769231, 1.3829787234042554],\n",
       "  [365, 547, 47, 52, 1898.0, 0.9038461538461539, 1.1063829787234043],\n",
       "  [349, 550, 53, 46, 1962.5, 1.1521739130434783, 0.8679245283018868],\n",
       "  [338, 549, 53, 46, 1888.0, 1.1521739130434783, 0.8679245283018868],\n",
       "  [330, 549, 52, 59, 2119.0, 0.8813559322033898, 1.1346153846153846],\n",
       "  [323, 549, 48, 69, 2319.5, 0.6956521739130435, 1.4375],\n",
       "  [313, 553, 49, 72, 2447.0, 0.6805555555555556, 1.469387755102041],\n",
       "  [302, 562, 49, 63, 2215.5, 0.7777777777777778, 1.2857142857142858],\n",
       "  [288, 576, 52, 49, 2017.5, 1.0612244897959184, 0.9423076923076923],\n",
       "  [274, 570, 55, 49, 1988.5, 1.1224489795918366, 0.8909090909090909],\n",
       "  [262, 567, 55, 59, 2281.5, 0.9322033898305084, 1.0727272727272728],\n",
       "  [251, 568, 55, 68, 2661.0, 0.8088235294117647, 1.2363636363636363],\n",
       "  [242, 570, 53, 74, 2889.5, 0.7162162162162162, 1.3962264150943395],\n",
       "  [229, 575, 53, 71, 2799.0, 0.7464788732394366, 1.3396226415094339],\n",
       "  [216, 585, 53, 61, 2479.0, 0.8688524590163934, 1.150943396226415],\n",
       "  [200, 586, 56, 54, 2284.5, 1.037037037037037, 0.9642857142857143],\n",
       "  [187, 581, 56, 61, 2542.5, 0.9180327868852459, 1.0892857142857142],\n",
       "  [172, 581, 58, 66, 2924.5, 0.8787878787878788, 1.1379310344827587],\n",
       "  [159, 581, 59, 71, 3278.5, 0.8309859154929577, 1.2033898305084745],\n",
       "  [147, 582, 57, 73, 3280.0, 0.7808219178082192, 1.280701754385965],\n",
       "  [133, 584, 57, 73, 3282.0, 0.7808219178082192, 1.280701754385965],\n",
       "  [119, 589, 56, 68, 2997.0, 0.8235294117647058, 1.2142857142857142],\n",
       "  [103, 597, 57, 57, 2586.0, 1.0, 1.0],\n",
       "  [86, 584, 60, 61, 2544.0, 0.9836065573770492, 1.0166666666666666],\n",
       "  [70, 579, 61, 66, 2936.0, 0.9242424242424242, 1.0819672131147542],\n",
       "  [55, 577, 61, 71, 3284.0, 0.8591549295774648, 1.1639344262295082],\n",
       "  [42, 577, 61, 74, 3462.5, 0.8243243243243243, 1.2131147540983607],\n",
       "  [27, 577, 60, 74, 3441.0, 0.8108108108108109, 1.2333333333333334],\n",
       "  [18, 580, 54, 70, 2907.5, 0.7714285714285715, 1.2962962962962963],\n",
       "  [4, 573, 53, 67, 2419.5, 0.7910447761194029, 1.2641509433962264],\n",
       "  [0, 565, 43, 63, 2033.5, 0.6825396825396826, 1.4651162790697674],\n",
       "  [0, 565, 30, 64, 1509.5, 0.46875, 2.1333333333333333],\n",
       "  [0, 569, 16, 60, 692.5, 0.26666666666666666, 3.75]],\n",
       " 'image': array([[[28, 25, 25],\n",
       "         [27, 24, 25],\n",
       "         [26, 25, 25],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[28, 24, 25],\n",
       "         [28, 25, 25],\n",
       "         [26, 24, 25],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [26, 23, 25],\n",
       "         [26, 25, 25],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [28, 25, 26],\n",
       "         [27, 25, 25],\n",
       "         ...,\n",
       "         [46, 44, 49],\n",
       "         [41, 40, 45],\n",
       "         [39, 38, 42]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [28, 25, 26],\n",
       "         [27, 25, 25],\n",
       "         ...,\n",
       "         [40, 39, 43],\n",
       "         [38, 36, 42],\n",
       "         [37, 36, 40]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [28, 25, 26],\n",
       "         [27, 25, 25],\n",
       "         ...,\n",
       "         [39, 38, 41],\n",
       "         [39, 37, 42],\n",
       "         [37, 36, 40]]], dtype=uint8)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de llamada a la funcion \n",
    "\n",
    "video_path = \"./ave.mp4\"\n",
    "mostrar_detección(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8d2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para caracterizar el movimiento\n",
    "# detecta objeto y define el rectángulo del contorno\n",
    "#\n",
    "# con el array de rectángulos de la deteccion se extrae:\n",
    "#\n",
    "# x,y,w,h: define el rectangulo como coordenadas (x,y) iniciales w:ancho h:alto\n",
    "# área del contorno (pixeles^2)\n",
    "# w/h: ratio ancho/alto\n",
    "# h/w: ratio alto/ancho\n",
    "\n",
    "def extraccion_deteccion (video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    output_widget = widgets.Output()\n",
    "    display(output_widget)\n",
    "    \n",
    "    total_frames, fps, tamaño_frame,duracion = obtener_metadatos(video_path)\n",
    "    \n",
    "        \n",
    "    # inicialización de variables\n",
    "    \n",
    "    (x,y,w,h)=(0,0,0,0)\n",
    "    rectangulos=[]\n",
    "        \n",
    "        \n",
    "    while cap.isOpened():\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=5)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            \n",
    "            #si el contorno es menor del umbral \n",
    "            \n",
    "            if cv2.contourArea(contour) < umbral_contorno:\n",
    "                continue\n",
    "            \n",
    "            rectangulos.append([x,y,w,h,cv2.contourArea(contour),w/h,h/w])\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "                                         \n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "                      \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "   \n",
    "    return {'fps':fps,'rectangulos':rectangulos}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e36ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extracción de variables\n",
    "#\n",
    "# con el array de rectángulos de la deteccion se extrae: (funcion independiente)\n",
    "#\n",
    "# - Tiempo del objeto detectado en segundos\n",
    "# - Variabilidad (cociente entre el máximo y mínimo tamaño de los contornos)\n",
    "# - Si tiene o no estela:ratio de h/v\n",
    "# - R2 (ajuste lineal)\n",
    "\n",
    "def extraccion_variables(p_deteccion):\n",
    "\n",
    "    deteccion=p_deteccion['rectangulos']\n",
    "\n",
    "    frames_deteccion = len([sub_arr[4] for sub_arr in deteccion if len(sub_arr) > 4 and sub_arr[4] > umbral_contorno])\n",
    "    \n",
    "    if frames_deteccion <5:\n",
    "        return {'num_frames_deteccion':frames_deteccion,'variabilidad':0,'max_contorno':0,'min_contorno':0,\n",
    "                'estelaH':0,'estelaV':0,'estela':0,'R2':0}\n",
    "    \n",
    "    \n",
    "    max_contorno = max([sub_arr[4] for sub_arr in deteccion if len(sub_arr) > 4 and sub_arr[4] > umbral_contorno])\n",
    "    min_contorno = min([sub_arr[4] for sub_arr in deteccion if len(sub_arr) > 4 and sub_arr[4] > umbral_contorno])\n",
    "    variabilidad = max_contorno / min_contorno\n",
    "    \n",
    "    ratio_estelaH = max([sub_arr[3]/sub_arr[2] for sub_arr in deteccion if len(sub_arr) > 4 \n",
    "                         and sub_arr[4] > umbral_contorno])\n",
    "    ratio_estelaV = max([sub_arr[2]/sub_arr[3] for sub_arr in deteccion if len(sub_arr) > 4 \n",
    "                         and sub_arr[4] > umbral_contorno])\n",
    "    ratio_estela = max (ratio_estelaH,ratio_estelaV)\n",
    "    \n",
    "    selected_points = [deteccion[0], deteccion[len(deteccion)//4], deteccion[len(deteccion)//2], \n",
    "                       deteccion[3*len(deteccion)//4], deteccion[-1]]\n",
    "\n",
    "    # Separar las coordenadas en dos listas (x e y)\n",
    "    x = [vector[0] + (vector[2]/2) for vector in selected_points]\n",
    "    y = [vector[1] + (vector[3]/2) for vector in selected_points]\n",
    "    \n",
    "        \n",
    "    # Ajuste lineal usando scipy\n",
    "    \n",
    "    try: \n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "    except ValueError as e:\n",
    "        \n",
    "    # Comprueba si el mensaje de error\n",
    "    \n",
    "        if str(e) == \"Cannot calculate a linear regression if all x values are identical\":\n",
    "            print(\"Error: Todos los valores de x son idénticos. No se puede calcular la regresión lineal.\")\n",
    "            return {'num_frames_deteccion':frames_deteccion,'variabilidad':variabilidad,'max_contorno':max_contorno,\n",
    "                    'min_contorno':min_contorno,'estelaH':ratio_estelaH,'estelaV':ratio_estelaV,'estela':ratio_estela,\n",
    "                    'R2':0}\n",
    "    \n",
    "        else:\n",
    "            raise\n",
    "        \n",
    "    return {'num_frames_deteccion':frames_deteccion,'variabilidad':variabilidad,'max_contorno':max_contorno,\n",
    "           'min_contorno':min_contorno,'estelaH':ratio_estelaH,'estelaV':ratio_estelaV,'estela':ratio_estela,\n",
    "            'R2':r_value**2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba16d8",
   "metadata": {},
   "source": [
    "Para extraer las variables de un conjunto de videos, la función extraccion_variables_lote devuelve un dataframe con el resultado de la extracción de los videos de un directorio dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0caf4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extraccion_variables_lote(path,clase,fichero_variables):\n",
    "\n",
    "# Extrae variables para un directorio que contiene videos mp4\n",
    "# Dado un path, clase (1: bolido y 0: no bolido), fichero_variables donde se escribiran csv para entrenamiento\n",
    "# \n",
    "# Escribe fichero_variables como csv con: \n",
    "#      Nombre de fichero mp4\n",
    "#      Clase (1 o 0)\n",
    "#      Tiempo de detección en segundos\n",
    "#      Array con variables:\n",
    "#      Variabilidad (tamaño de rectángulo)\n",
    "#      Si tiene o no estela:ratio de h/v\n",
    "#      R2 ajuste trayectoria lineal\n",
    "\n",
    "    # Comprobar si el directorio existe\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(\"El directorio especificado no existe.\")\n",
    "        return\n",
    "    \n",
    "    # Lista para almacenar los datos antes de convertirlos a DataFrame\n",
    "    data = []\n",
    "    \n",
    "    # Recorrer los ficheros en el directorio\n",
    "    for filename in os.listdir(path):\n",
    "        print(filename)\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            \n",
    "            total_frames, fps, tamaño_frame,duracion = obtener_metadatos(os.path.join(path, filename))\n",
    "            \n",
    "            # Llamar a tu función extraccion_variables_lote\n",
    "            variables = extraccion_variables(extraccion_deteccion(os.path.join(path, filename)))\n",
    "            \n",
    "            # Añadir al dataset\n",
    "            data.append({\n",
    "                \"Nombre_Fichero\": filename,\n",
    "                \"Clase\": clase,\n",
    "                \"Tiempo_Deteccion\": variables['num_frames_deteccion']/fps,\n",
    "                \"Array_Resultado\": variables\n",
    "            })\n",
    "\n",
    "    # Convertir la lista de datos a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    df.to_csv(fichero_variables, index=False)\n",
    "\n",
    "    print(\"El procesamiento ha finalizado y los resultados se han guardado en\",path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e0d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de extracción de variables para el conjunto de datos de entrenamiento clase 1: Bólidos\n",
    "# Descomentar para ejecutar (el proceso tarda unos 20 minutos)\n",
    " \n",
    "# extraccion_variables_lote (\"./meteor\",1,\"./clase1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64bd1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de extracción de variables para el conjunto de datos de entrenamiento clase 0: No Bólidos\n",
    "# Descomentar para ejecutar (el proceso tarda unos 20 minutos)\n",
    "\n",
    "#extraccion_variables_lote (\"./non_meteor\",0,\"./clase0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5902b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea dataset para entrenamiento desde un fichero csv: file\n",
    "\n",
    "import ast\n",
    "def crear_dataset (file):\n",
    "\n",
    "    bolidos = pd.read_csv(file, sep = ',') # carga del CSV, usando como separador , 'comas'\n",
    "    \n",
    "    bolidos['Array_Resultado'] = bolidos['Array_Resultado'].apply(ast.literal_eval)\n",
    "\n",
    "    bolidos = bolidos.join(pd.json_normalize(bolidos['Array_Resultado'])).drop(columns=['Array_Resultado'])\n",
    "    \n",
    "    #bolidos['R2'] = bolidos['R2'].astype(float)\n",
    "    \n",
    "    bolidos['R2'] = pd.to_numeric(bolidos['R2'], errors='coerce')\n",
    "\n",
    "    return bolidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24eefc",
   "metadata": {},
   "source": [
    "# Codigo Entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a86040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de conjuntos de entrenamiento: variables de entrada (X) y salida (y) (6865, 9) (6865, 1)\n",
      "Dimensiones de conjuntos de validación: variables de entrada (X) y salida (y) (2943, 9) (2943, 1)\n"
     ]
    }
   ],
   "source": [
    "# Codigo Entrenamiento\n",
    "\n",
    "# carga inicial dataframe df_bolidos con ammbas clases (0 y 1  para negativos y para positivos)\n",
    "\n",
    "df_bolidos = pd.concat([crear_dataset(\"./clase1.csv\"),crear_dataset(\"./clase0.csv\")])\n",
    "df_bolidos = df_bolidos.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Se limpia el dataframe df_bolidos antes del seguir procesando:\n",
    "# - eliminando los de clase 0 y 1 con 0 frames_deteccion: el algoritmo de deteccion ha fallado\n",
    "# - eliminamos los de clase 0 y 1 con 'NA' por fallo en la regresión lineal de trayectoria\n",
    "\n",
    "df_filtrado = df_bolidos[df_bolidos['num_frames_deteccion'] > 0]\n",
    "df_filtrado = df_filtrado[df_filtrado['R2'] > 0]\n",
    "\n",
    "\n",
    "# Se separan en df_X y df_Y para los dataset de entrenamiento\n",
    "\n",
    "df_X = df_filtrado [['Tiempo_Deteccion','num_frames_deteccion','variabilidad','max_contorno','min_contorno','estelaH','estelaV','estela','R2']]\n",
    "df_Y = df_filtrado [['Clase']]\n",
    "\n",
    "#df_X = df_bolidos [['Tiempo_Deteccion','num_frames_deteccion','variabilidad','max_contorno','min_contorno','estelaH','estelaV','estela','R2']]\n",
    "#df_Y = df_bolidos [['Clase']]\n",
    "\n",
    "\n",
    "# Separamos en train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilizamos una proporción 70/30. El parámetro random_state lo utilizamos para obtener los mismos resultados siempre\n",
    "X_bolidos_train, X_bolidos_test, y_bolidos_train, y_bolidos_test = train_test_split(df_X, df_Y,test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(\"Dimensiones de conjuntos de entrenamiento: variables de entrada (X) y salida (y)\", X_bolidos_train.shape, y_bolidos_train.shape)\n",
    "print(\"Dimensiones de conjuntos de validación: variables de entrada (X) y salida (y)\",X_bolidos_test.shape, y_bolidos_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5505b0",
   "metadata": {},
   "source": [
    "Entrenamiento de módelos\n",
    "Se van a entrenar varios modelos de Clasificación:\n",
    "\n",
    "* Regresión Logística\n",
    "* Árbol de Decisión\n",
    "* KNN\n",
    "* SVC\n",
    "* Redes Neuronales\n",
    "\n",
    "Y se obtendrán las métricas de recall, precisión y matriz de confusión para analizar su rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8dea49",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3aa8d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train:  0.9367807720320466\n",
      "Accuracy en test:  0.9367991845056065\n",
      "Precision: 0.937\n",
      "Recall 0.937\n",
      "[[1775  158]\n",
      " [  28  982]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Creamos el objeto del modelo,fijando la semilla para evitar aleatoriedad. Se sube el parametro max_iter para que finalice\n",
    "logreg = LogisticRegression(random_state=42,max_iter=10000)\n",
    "\n",
    "# Entrenamos con el conjunto de train y su target\n",
    "X_bolidos_train = X_bolidos_train.select_dtypes(include = 'number')\n",
    "X_bolidos_test = X_bolidos_test.select_dtypes(include = 'number')\n",
    "\n",
    "logreg.fit(X_bolidos_train, y_bolidos_train[['Clase']].values.ravel())\n",
    "logreg.coef_.shape\n",
    "\n",
    "print('Accuracy en train: ', logreg.score(X_bolidos_train, y_bolidos_train[['Clase']]))\n",
    "print('Accuracy en test: ', logreg.score(X_bolidos_test, y_bolidos_test[['Clase']]))\n",
    "\n",
    "# Calculamos las métricas globales, con el parámetro average\n",
    "\n",
    "preds_proy = logreg.predict(X_bolidos_test)\n",
    "probs_proy = logreg.predict_proba(X_bolidos_test)\n",
    "precision = precision_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "recall = recall_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "cm = confusion_matrix(y_bolidos_test[['Clase']], preds_proy)\n",
    "\n",
    "print('Precision: %.3f' % precision)\n",
    "print('Recall %.3f' % recall)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df15d7",
   "metadata": {},
   "source": [
    "# Arból de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f10f241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train:  1.0\n",
      "Accuracy en test:  0.9364593951749915\n",
      "Precision: 0.936\n",
      "Recall 0.936\n",
      "[[1834   99]\n",
      " [  88  922]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Inicialiamos con sus parámetros por defecto (salvo la semilla)\n",
    "tree_class = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "# Entrenamiento\n",
    "tree_class.fit(X_bolidos_train, y_bolidos_train[['Clase']])\n",
    "print('Accuracy en train: ',tree_class.score(X_bolidos_train, y_bolidos_train[['Clase']]))\n",
    "print('Accuracy en test: ', tree_class.score(X_bolidos_test, y_bolidos_test[['Clase']]))\n",
    "\n",
    "# Calculamos las métricas globales, con el parámetro average\n",
    "\n",
    "preds_proy = tree_class.predict(X_bolidos_test)\n",
    "probs_proy = tree_class.predict_proba(X_bolidos_test)\n",
    "precision = precision_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "recall = recall_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "cm = confusion_matrix(y_bolidos_test[['Clase']], preds_proy)\n",
    "\n",
    "print('Precision: %.3f' % precision)\n",
    "print('Recall %.3f' % recall)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb903a4",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2533b9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train:  0.9238164603058995\n",
      "Accuracy en test:  0.8854909955827387\n",
      "Precision: 0.885\n",
      "Recall 0.885\n",
      "[[1723  210]\n",
      " [ 127  883]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Por defecto, k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_bolidos_train, y_bolidos_train[['Clase']].values.ravel())\n",
    "print('Accuracy en train: ',knn.score(X_bolidos_train, y_bolidos_train[['Clase']]))\n",
    "print('Accuracy en test: ',knn.score(X_bolidos_test, y_bolidos_test[['Clase']]))\n",
    "\n",
    "preds_proy = knn.predict(X_bolidos_test)\n",
    "probs_proy = knn.predict_proba(X_bolidos_test)\n",
    "precision = precision_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "recall = recall_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "cm = confusion_matrix(y_bolidos_test[['Clase']], preds_proy)\n",
    "\n",
    "print('Precision: %.3f' % precision)\n",
    "print('Recall %.3f' % recall)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a6d68",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88269fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train:  0.8569555717407138\n",
      "Accuracy en test:  0.8501529051987767\n",
      "Precision: 0.850\n",
      "Recall 0.850\n",
      "[[1518  415]\n",
      " [  26  984]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state=42,probability=True) # parámetros por defecto\n",
    "\n",
    "svc.fit(X_bolidos_train, y_bolidos_train[['Clase']].values.ravel())\n",
    "print('Accuracy en train: ',svc.score(X_bolidos_train, y_bolidos_train[['Clase']]))\n",
    "print('Accuracy en test: ',svc.score(X_bolidos_test, y_bolidos_test[['Clase']]))\n",
    "\n",
    "preds_proy = svc.predict(X_bolidos_test)\n",
    "probs_proy = svc.predict_proba(X_bolidos_test)\n",
    "precision = precision_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "recall = recall_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "cm = confusion_matrix(y_bolidos_test[['Clase']], preds_proy)\n",
    "\n",
    "print('Precision: %.3f' % precision)\n",
    "print('Recall %.3f' % recall)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a3f11",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b92867eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train:  0.9159504734158777\n",
      "Accuracy en test:  0.9119945633707102\n",
      "Precision: 0.912\n",
      "Recall 0.912\n",
      "[[1704  229]\n",
      " [  30  980]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state = 42,max_iter=1500)\n",
    "\n",
    "mlp.fit(X_bolidos_train, y_bolidos_train[['Clase']].values.ravel())\n",
    "\n",
    "print('Accuracy en train: ',mlp.score(X_bolidos_train, y_bolidos_train[['Clase']]))\n",
    "print('Accuracy en test: ',mlp.score(X_bolidos_test, y_bolidos_test[['Clase']]))\n",
    "\n",
    "preds_proy = mlp.predict(X_bolidos_test)\n",
    "probs_proy = mlp.predict_proba(X_bolidos_test)\n",
    "precision = precision_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "recall = recall_score(y_bolidos_test[['Clase']], preds_proy, average = 'micro')\n",
    "cm = confusion_matrix(y_bolidos_test[['Clase']], preds_proy)\n",
    "\n",
    "print('Precision: %.3f' % precision)\n",
    "print('Recall %.3f' % recall)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee3da4",
   "metadata": {},
   "source": [
    "# Combinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188e18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy modelo combinado: 0.922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Combinamos los 3 modelos anteriores (excluyendo a Vector Soporte por ser el peor)\n",
    "vc = VotingClassifier(estimators = [('mlp',mlp),('logreg',logreg),('tree_class',tree_class),('svc',svc),('knn',knn)])\n",
    "                      \n",
    "# ojo con train no con test\n",
    "\n",
    "vc.fit(X_bolidos_train, y_bolidos_train.values.ravel())\n",
    "\n",
    "print('Accuracy modelo combinado: %.3f' % vc.score(X_bolidos_test, y_bolidos_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97fef6",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6a5340b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'kernel': 'linear'}\n",
      "0.9395479647773226\n",
      "SVC(C=10.0, kernel='linear', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parámetros de búsqueda y posibles valores\n",
    "grid_parameters = {'kernel': ['linear', 'rbf', 'poly'], 'C': [10.0, 1.0, 0.1, 0.01, 0.001]}\n",
    "\n",
    "# Grid search\n",
    "grid_SVC = GridSearchCV(SVC(random_state=42), param_grid = grid_parameters, cv = 3, scoring = 'accuracy')\n",
    "\n",
    "# Comenzamos el entrenamiento\n",
    "grid_SVC.fit(X_bolidos_train, y_bolidos_train.values.ravel())\n",
    "\n",
    "print(grid_SVC.best_params_)\n",
    "\n",
    "print(grid_SVC.best_score_)\n",
    "\n",
    "print(grid_SVC.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c8a7c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': (15, 15)}\n",
      "0.9373639230290607\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(15, 15), max_iter=1500,\n",
      "              random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parámetros de búsqueda y posibles valores\n",
    "grid_parameters = {'hidden_layer_sizes': [(20,), (30,), (15, 15)], \n",
    "                   'activation': ['tanh', 'relu'] }\n",
    "\n",
    "# Grid search\n",
    "grid_MLP = GridSearchCV(MLPClassifier(random_state=42,max_iter=1500), param_grid = grid_parameters, cv = 3, scoring = 'accuracy')\n",
    "\n",
    "# Comenzamos el entrenamiento\n",
    "grid_MLP.fit(X_bolidos_train, y_bolidos_train.values.ravel())\n",
    "\n",
    "print(grid_MLP.best_params_)\n",
    "\n",
    "print(grid_MLP.best_score_)\n",
    "\n",
    "print(grid_MLP.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8d426bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 6, 'splitter': 'best'}\n",
      "0.9418785215803566\n",
      "DecisionTreeClassifier(max_depth=6, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parámetros de búsqueda y posibles valores\n",
    "grid_parameters = {'criterion': ['gini', 'entropy', 'log_loss'], 'splitter': ['best', 'random'],'max_depth' : [1,2,3,4,5,6,7,8] }\n",
    "\n",
    "# Grid search\n",
    "grid_Tree = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid = grid_parameters, cv = 3, scoring = 'accuracy')\n",
    "\n",
    "# Comenzamos el entrenamiento\n",
    "grid_Tree.fit(X_bolidos_train, y_bolidos_train.values.ravel())\n",
    "\n",
    "print(grid_Tree.best_params_)\n",
    "\n",
    "print(grid_Tree.best_score_)\n",
    "\n",
    "print(grid_Tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8353c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 19}\n",
      "0.9002187649857198\n",
      "KNeighborsClassifier(n_neighbors=19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parámetros de búsqueda y posibles valores\n",
    "k_range = list(range(1, 31))\n",
    "grid_parameters = dict(n_neighbors=k_range)\n",
    "\n",
    "# Grid search\n",
    "grid_KNN = GridSearchCV(KNeighborsClassifier(),param_grid = grid_parameters, cv = 10, scoring = 'accuracy')\n",
    "\n",
    "# Comenzamos el entrenamiento\n",
    "grid_KNN.fit(X_bolidos_train, y_bolidos_train.values.ravel())\n",
    "\n",
    "print(grid_KNN.best_params_)\n",
    "\n",
    "print(grid_KNN.best_score_)\n",
    "\n",
    "print(grid_KNN.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = VotingClassifier(estimators = [('mlp',grid_MLP),('logreg',logreg),('tree_class',grid_Tree),('svc',grid_SVC),('knn',grid_KNN)])\n",
    "                      \n",
    "# ojo con train no con test\n",
    "\n",
    "vc.fit(X_bolidos_train, y_bolidos_train.values.ravel())\n",
    "\n",
    "print('Accuracy modelo combinado: %.3f' % vc.score(X_bolidos_test, y_bolidos_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f6048",
   "metadata": {},
   "source": [
    "# Guardamos modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f9f637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_combinado_final.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se almacena el modelo vc\n",
    "from joblib import dump\n",
    "\n",
    "dump(vc, 'modelo_combinado_final.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d77fb6",
   "metadata": {},
   "source": [
    "Evaluación de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0cc5939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894859e6cf564a02bab510ca95b11a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579134c26bbf47a9ae375bfdc02a276f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678e0ad4f59a4411adce8d3b1d288e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clasificacion es: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5468ef20f63949f0862c8d99a09e2bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05p\\x00\\x00\\x04@\\x08\\x02\\x00\\x00\\x00\\xc8\\xe0\\xec\\xe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Para un video mp4 se ejecuta el pipeline de detección y clasificación\n",
    "\n",
    "video_path=\"perseida1.mp4\"\n",
    "\n",
    "mostrar_detección(video_path)\n",
    "\n",
    "total_frames, fps, tamaño_frame,duracion = obtener_metadatos(video_path)\n",
    "D = extraccion_deteccion(video_path)\n",
    "X = extraccion_variables(D)\n",
    "\n",
    "df = pd.DataFrame(X,index=[0])\n",
    "\n",
    "df.insert(0, 'Tiempo_Deteccion', df['num_frames_deteccion'][0] / fps)\n",
    "\n",
    "clasificacion = vc.predict(df)\n",
    "\n",
    "print(\"La clasificacion es:\",clasificacion[0])\n",
    "\n",
    "imagen = cv2.imread('deteccion.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    " \n",
    "# Parámetros para cv2.putText\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "x_start = 10  # posición horizontal inicial\n",
    "y_start = 200  # posición vertical inicial\n",
    "y_offset = 30  # espacio entre líneas\n",
    "fontScale = 0.7  # tamaño de la fuente\n",
    "color = (0, 255, 0)  # color del texto en BGR\n",
    "texto = \"Bolido [1]\"\n",
    "thickness = 2  # grosor de la línea\n",
    "\n",
    "if clasificacion[0] == 0:\n",
    "    color = (0,0,255)\n",
    "    texto = \"No bolido [0]\"\n",
    "    \n",
    "cv2.putText(imagen,texto,(10,200), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "display(widgets.Image(value=cv2.imencode('.png', imagen)[1].tobytes()))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37f1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
